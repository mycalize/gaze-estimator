{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training a Simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from data.image_dataset import ImageDataset\n",
        "from training.cnn import ConvNet\n",
        "from training.train import *\n",
        "from training.eval import *\n",
        "from data.convert_labels import *\n",
        "\n",
        "# for auto-reloading external modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create ImageDataset\n",
        "annotations_file_path = 'data/real/01_20_160_120/01_20_160_120.csv'\n",
        "img_dir_path = 'data/real/01_20_160_120'\n",
        "\n",
        "# Can override arguments specifying class boundaries\n",
        "target_transform = lambda target: convert_labels(target)\n",
        "\n",
        "train_data = ImageDataset(\n",
        "  annotations_file=annotations_file_path,\n",
        "  img_dir=img_dir_path,\n",
        "  transform=None,\n",
        "  target_transform=target_transform\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 120, 160])\n",
            "Labels batch shape: torch.Size([64])\n",
            "tensor([15,  7,  6,  0, 11, 14,  6, 11,  9, 10,  0,  6,  5, 10,  8,  2, 11, 10,\n",
            "         8, 11, 10, 13, 13, 11,  1,  5,  1, 10,  1, 15, 13, 15, 14,  5, 10,  3,\n",
            "         8, 15,  6,  2, 14, 14, 13,  5,  9, 10,  0,  3,  9,  1,  2,  6,  6,  8,\n",
            "        11,  5,  8,  3, 14,  6, 10, 13,  1, 15])\n"
          ]
        }
      ],
      "source": [
        "# Create Dataloader\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "train_features, train_labels = next(iter(train_loader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "print(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ConvNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "results = train(model, criterion, optimizer, train_loader, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
