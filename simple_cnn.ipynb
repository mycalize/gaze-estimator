{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training a Simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import os\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from data.image_dataset import ImageDataset\n",
        "from models.cnn import CNN\n",
        "from models.nvgaze import NVGaze\n",
        "from training.train import *\n",
        "from training.eval import *\n",
        "from data.convert_labels import *\n",
        "from utils.dataset_utils import check_disjoint\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading external modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "subject = 1\n",
        "stride = 5\n",
        "input_dims = (127, 127)\n",
        "mode = 'reg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_subset = f'{subject:>02}_{stride:>02}_{input_dims[0]}_{input_dims[1]}'\n",
        "train_dir_path = f'data/real/{data_subset}/train'\n",
        "train_annotations_file_path = f'{train_dir_path}/{data_subset}_train.csv'\n",
        "val_dir_path = f'data/real/{data_subset}/val'\n",
        "val_annotations_file_path = f'{val_dir_path}/{data_subset}_val.csv'\n",
        "test_dir_path = f'data/real/{data_subset}/test'\n",
        "test_annotations_file_path = f'{test_dir_path}/{data_subset}_test.csv'\n",
        "\n",
        "target_transform = None if mode == 'reg' else (lambda target: convert_labels(target))\n",
        "\n",
        "train_dataset = ImageDataset(\n",
        "  annotations_file=train_annotations_file_path,\n",
        "  img_dir=train_dir_path,\n",
        "  transform=None,\n",
        "  target_transform=target_transform\n",
        ")\n",
        "val_dataset = ImageDataset(\n",
        "  annotations_file=val_annotations_file_path,\n",
        "  img_dir=val_dir_path,\n",
        "  transform=None,\n",
        "  target_transform=target_transform\n",
        ")\n",
        "test_dataset = ImageDataset(\n",
        "  annotations_file=test_annotations_file_path,\n",
        "  img_dir=test_dir_path,\n",
        "  transform=None,\n",
        "  target_transform=target_transform\n",
        ")\n",
        "\n",
        "assert(check_disjoint(val_dataset, test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Dataloader\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "train_features, train_labels = next(iter(train_loader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Label batch shape: {train_labels.size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model = CNN(input_dims=input_dims)\n",
        "out_num_features = 2 if mode == 'reg' else 16\n",
        "model = NVGaze(input_dims=input_dims, out_num_features=out_num_features)\n",
        "criterion = nn.MSELoss() if mode == 'reg' else nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.99, weight_decay=0.1, nesterov=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Set-up GPU device (if available) and move model\n",
        "device = torch.device('mps' if torch.mps.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "results = train(model, device, mode, criterion, optimizer, train_loader, val_loader, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_history, train_perf_history, val_perf_history = results\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(loss_history, 'o')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_perf_history, '-o')\n",
        "plt.plot(val_perf_history, '-o')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error' if mode == 'reg' else 'Accuracy')\n",
        "\n",
        "fig = plt.gcf()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if mode == 'reg':\n",
        "  train_error = evaluate_error(model, device, train_loader)\n",
        "  val_error = evaluate_error(model, device, val_loader)\n",
        "  test_error = evaluate_error(model, device, test_loader)\n",
        "  train_error_str = f'Train err: {train_error.item():.6f} ({np.rad2deg(train_error.item()):.2f}°)'\n",
        "  val_error_str = f'Val err:   {val_error.item():.6f} ({np.rad2deg(val_error.item()):.2f}°)'\n",
        "  test_error_str = f'Test err:  {test_error.item():.6f} ({np.rad2deg(test_error.item()):.2f}°)'\n",
        "  error_summary = [train_error_str, val_error_str, test_error_str]\n",
        "  error_summary_str = '\\n'.join(error_summary)\n",
        "  print(error_summary_str)\n",
        "else:\n",
        "  test_acc = evaluate_acc(model, device, test_loader)\n",
        "  print(f'Test acc: {test_acc.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save current model\n",
        "s = datetime.fromtimestamp(time.time()).strftime('%m-%d--%H-%M-%S')\n",
        "dir_path = f'models/saved_models/{s}'\n",
        "\n",
        "os.mkdir(dir_path)\n",
        "with open(f'{dir_path}/{s}.txt', 'w') as f:\n",
        "  f.write(error_summary_str)\n",
        "  f.write('\\n\\n')\n",
        "  for i, (train_err, val_err) in enumerate(zip(train_perf_history, val_perf_history)):\n",
        "    f.write(f'| Epoch {i + 1:2d} | Train err {train_err:.6f} | Val err {val_err:.6f} |\\n')\n",
        "fig.savefig(f'{dir_path}/{s}.png')\n",
        "torch.save(model.state_dict(), f'{dir_path}/{s}.pt')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
